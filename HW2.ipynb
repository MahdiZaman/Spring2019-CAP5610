{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiZaman/Spring2019-CAP5610/blob/master/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Y2HofE0pHJZP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**************HW 2**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The goal of this homework is to create a convolutional neural network for the CIFAR10 data set. See this colab notebook how to load the CIFAR data in Keras.\n",
        "\n",
        "You should not use any pretrained convnets that come with Keras. You have to create and train your own convnets with Keras from scratch.\n",
        "\n",
        "\n",
        "\n",
        "*   Simple hold-out validation\n",
        "\n",
        "Make sure that the data is divided into:\n",
        "\n",
        "training set (80%)\n",
        "validation set (20%)\n",
        "test set.\n",
        "Use the training set to train your neural networks. Evaluate their performance on the validation data set.\n",
        "\n",
        "After trying several different architectures, choose the one that performs best of the validation set. Try at least four different architectures by using data augmentation, using dropout, varying the number of layers, the number of filters, etc.\n",
        "\n",
        "Train this final architecture on the data from the training set and validation set and evaluate its performance on the test set.\n",
        "\n",
        "*   k-fold validation\n",
        "\n",
        "Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "6Alftzj_PcHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Libraries and Loading Dataset**"
      ]
    },
    {
      "metadata": {
        "id": "ZCbODkRdEWWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels) = cifar10.load_data()\n",
        "# (train_images_original, train_labels_original), (test_images_original, test_labels_n) = cifar10.load_data() #categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eGoDyDqmPlV3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Reshaping and Normalizing Training and Test Samples**"
      ]
    },
    {
      "metadata": {
        "id": "0uXQebz9lWmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images_rshp = train_images_original.reshape((train_images_original.shape[0], train_images_original.shape[1], train_images_original.shape[2], train_images_original.shape[3]))\n",
        "test_images_rshp = test_images_original.reshape((test_images_original.shape[0], test_images_original.shape[1], test_images_original.shape[2], test_images_original.shape[3]))\n",
        "\n",
        "train_images_n = train_images_rshp.astype('float32') / 255.0\n",
        "test_images = test_images_rshp.astype('float32') / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7wdFvhgPwYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Simple Hold-out Validation***"
      ]
    },
    {
      "metadata": {
        "id": "F32NQol4aA57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indices = np.random.permutation(train_images_original.shape[0])\n",
        "val_indcs = indices[0:10000]\n",
        "val_images = train_images_n[val_indcs]\n",
        "val_labels = train_labels_original[val_indcs]\n",
        "# val_labels_n = train_labels_original[val_indcs] #categorical\n",
        "\n",
        "\n",
        "train_indcs = indices[10000:]\n",
        "train_images = train_images_n[train_indcs]\n",
        "train_labels = train_labels_original[train_indcs]\n",
        "# train_labels_n = train_labels_original[train_indcs] #categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVCQ_gA3O5r1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_labels = np_utils.to_categorical(train_labels_n, 10)\n",
        "# val_labels = np_utils.to_categorical(val_labels_n, 10)\n",
        "# test_labels = np_utils.to_categorical(test_labels_n, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L894H3F8_pe8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initializations\n",
        "\n",
        "weight_decay = 1e-4  #For Kernel Regularizers\n",
        "epochs = 50\n",
        "batch_size=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fW4lVIVvTHMR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.) **Baseline Model**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DEzuqM-_HKYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set up the layers\n",
        "## Baseline\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    #\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    #\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    #\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=50,  \n",
        "                      validation_data=(val_images, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yYuuempsTclh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2.) **Deeper Architecture w/ More Layers and Filters, Drop-Out, and L2 Regularizer**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pI63Qug9Xqs3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape= (32,32,3), strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.30),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.35),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.40),\n",
        "  \n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.50),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "epochs = 50\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,  \n",
        "                      validation_data=(val_images, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F1XhcW6I-IrC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3) Adding Data Augmentation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mG8t5RlFS9PG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.15,\n",
        "        height_shift_range=0.15,\n",
        "        shear_range=0.15,\n",
        "        zoom_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "datagen.fit(train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5xQyvkb2_Fnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "366b1a45-3813-42d5-8113-9ed22577768a"
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape= (32,32,3), strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.30),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.35),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.40),\n",
        "  \n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.50),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,980,010\n",
            "Trainable params: 4,980,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnWytUzhB8yD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1055
        },
        "outputId": "b9adf498-1832-4fee-abd6-14646dc8fd60"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(train_images, train_labels, batch_size=32),\\\n",
        "                    steps_per_epoch=train_images.shape[0] // batch_size, epochs=50,\\\n",
        "                    verbose=1,validation_data=(val_images,val_labels))\n",
        "\n",
        "# model.fit_generator(datagen.flow(train_images, train_labels, batch_size=32), steps_per_epoch=train_images.shape[0] // batch_size, epochs= 50, verbose=1, validation_data=(val_images,val_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10000/10000 [==============================] - 4s 399us/sample - loss: 1.9822 - acc: 0.2940\n",
            "1250/1250 [==============================] - 59s 47ms/step - loss: 2.3183 - acc: 0.1953 - val_loss: 1.9822 - val_acc: 0.2940\n",
            "Epoch 2/50\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.7568 - acc: 0.3690\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.9345 - acc: 0.3070 - val_loss: 1.7569 - val_acc: 0.3690\n",
            "Epoch 3/50\n",
            "10000/10000 [==============================] - 4s 365us/sample - loss: 1.5454 - acc: 0.4517\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.7507 - acc: 0.3742 - val_loss: 1.5452 - val_acc: 0.4517\n",
            "Epoch 4/50\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.4374 - acc: 0.4973\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.6393 - acc: 0.4309 - val_loss: 1.4376 - val_acc: 0.4973\n",
            "Epoch 5/50\n",
            "10000/10000 [==============================] - 4s 365us/sample - loss: 1.4606 - acc: 0.5004\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.5789 - acc: 0.4614 - val_loss: 1.4609 - val_acc: 0.5004\n",
            "Epoch 6/50\n",
            "10000/10000 [==============================] - 4s 373us/sample - loss: 1.4119 - acc: 0.5178\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.5271 - acc: 0.4870 - val_loss: 1.4120 - val_acc: 0.5178\n",
            "Epoch 7/50\n",
            "10000/10000 [==============================] - 4s 372us/sample - loss: 1.3454 - acc: 0.5470\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.4934 - acc: 0.5074 - val_loss: 1.3456 - val_acc: 0.5470\n",
            "Epoch 8/50\n",
            "10000/10000 [==============================] - 4s 362us/sample - loss: 1.3567 - acc: 0.5547\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.4492 - acc: 0.5270 - val_loss: 1.3569 - val_acc: 0.5547\n",
            "Epoch 9/50\n",
            "10000/10000 [==============================] - 4s 362us/sample - loss: 1.3033 - acc: 0.5685\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.4275 - acc: 0.5404 - val_loss: 1.3033 - val_acc: 0.5685\n",
            "Epoch 10/50\n",
            "10000/10000 [==============================] - 4s 376us/sample - loss: 1.2763 - acc: 0.5741\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.4028 - acc: 0.5542 - val_loss: 1.2763 - val_acc: 0.5741\n",
            "Epoch 11/50\n",
            "10000/10000 [==============================] - 4s 372us/sample - loss: 1.2117 - acc: 0.6046\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.3809 - acc: 0.5625 - val_loss: 1.2118 - val_acc: 0.6046\n",
            "Epoch 12/50\n",
            "10000/10000 [==============================] - 4s 364us/sample - loss: 1.1863 - acc: 0.6326\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.3633 - acc: 0.5716 - val_loss: 1.1860 - val_acc: 0.6326\n",
            "Epoch 13/50\n",
            "10000/10000 [==============================] - 4s 356us/sample - loss: 1.3189 - acc: 0.5862\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.3554 - acc: 0.5767 - val_loss: 1.3191 - val_acc: 0.5862\n",
            "Epoch 14/50\n",
            "10000/10000 [==============================] - 4s 374us/sample - loss: 1.1642 - acc: 0.6330\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.3340 - acc: 0.5885 - val_loss: 1.1643 - val_acc: 0.6330\n",
            "Epoch 15/50\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.1012 - acc: 0.6554\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.3242 - acc: 0.5914 - val_loss: 1.1010 - val_acc: 0.6554\n",
            "Epoch 16/50\n",
            "10000/10000 [==============================] - 4s 359us/sample - loss: 1.1815 - acc: 0.6222\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.3207 - acc: 0.5944 - val_loss: 1.1821 - val_acc: 0.6222\n",
            "Epoch 17/50\n",
            "10000/10000 [==============================] - 4s 362us/sample - loss: 1.1339 - acc: 0.6620\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.3006 - acc: 0.6054 - val_loss: 1.1337 - val_acc: 0.6620\n",
            "Epoch 18/50\n",
            "10000/10000 [==============================] - 4s 372us/sample - loss: 1.3744 - acc: 0.6085\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2922 - acc: 0.6114 - val_loss: 1.3750 - val_acc: 0.6085\n",
            "Epoch 19/50\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.1176 - acc: 0.6556\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2925 - acc: 0.6076 - val_loss: 1.1175 - val_acc: 0.6556\n",
            "Epoch 20/50\n",
            " 467/1250 [==========>...................] - ETA: 33s - loss: 1.2902 - acc: 0.6109"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hj2cuxv2SN55",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}