{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiZaman/Spring2019-CAP5610/blob/master/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Y2HofE0pHJZP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**************HW 2**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The goal of this homework is to create a convolutional neural network for the CIFAR10 data set. See this colab notebook how to load the CIFAR data in Keras.\n",
        "\n",
        "You should not use any pretrained convnets that come with Keras. You have to create and train your own convnets with Keras from scratch.\n",
        "\n",
        "\n",
        "\n",
        "*   Simple hold-out validation\n",
        "\n",
        "Make sure that the data is divided into:\n",
        "\n",
        "training set (80%)\n",
        "validation set (20%)\n",
        "test set.\n",
        "Use the training set to train your neural networks. Evaluate their performance on the validation data set.\n",
        "\n",
        "After trying several different architectures, choose the one that performs best of the validation set. Try at least four different architectures by using data augmentation, using dropout, varying the number of layers, the number of filters, etc.\n",
        "\n",
        "Train this final architecture on the data from the training set and validation set and evaluate its performance on the test set.\n",
        "\n",
        "*   k-fold validation\n",
        "\n",
        "Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "6Alftzj_PcHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Libraries and Loading Dataset**"
      ]
    },
    {
      "metadata": {
        "id": "ZCbODkRdEWWV",
        "colab_type": "code",
        "outputId": "ee8f3f02-d638-419e-f8fb-2127d9c504d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels) = cifar10.load_data()\n",
        "# (train_images_original, train_labels_original), (test_images_original, test_labels_n) = cifar10.load_data() #categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 20s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eGoDyDqmPlV3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Reshaping and Normalizing Training and Test Samples**"
      ]
    },
    {
      "metadata": {
        "id": "0uXQebz9lWmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images_rshp = train_images_original.reshape((train_images_original.shape[0], train_images_original.shape[1], train_images_original.shape[2], train_images_original.shape[3]))\n",
        "test_images_rshp = test_images_original.reshape((test_images_original.shape[0], test_images_original.shape[1], test_images_original.shape[2], test_images_original.shape[3]))\n",
        "\n",
        "train_images_n = train_images_rshp.astype('float32') / 255.0\n",
        "test_images = test_images_rshp.astype('float32') / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7wdFvhgPwYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Simple Hold-out Validation***"
      ]
    },
    {
      "metadata": {
        "id": "F32NQol4aA57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indices = np.random.permutation(train_images_original.shape[0])\n",
        "val_indcs = indices[0:10000]\n",
        "val_images = train_images_n[val_indcs]\n",
        "val_labels = train_labels_original[val_indcs]\n",
        "# val_labels_n = train_labels_original[val_indcs] #categorical\n",
        "\n",
        "\n",
        "train_indcs = indices[10000:]\n",
        "train_images = train_images_n[train_indcs]\n",
        "train_labels = train_labels_original[train_indcs]\n",
        "# train_labels_n = train_labels_original[train_indcs] #categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVCQ_gA3O5r1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_labels = np_utils.to_categorical(train_labels_n, 10)\n",
        "# val_labels = np_utils.to_categorical(val_labels_n, 10)\n",
        "# test_labels = np_utils.to_categorical(test_labels_n, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L894H3F8_pe8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initializations\n",
        "\n",
        "weight_decay = 1e-4  #For Kernel Regularizers\n",
        "epochs = 80\n",
        "batch_size=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fW4lVIVvTHMR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.) **Baseline Model**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DEzuqM-_HKYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set up the layers\n",
        "## Baseline\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    #\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    #\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    #\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=50,  \n",
        "                      validation_data=(val_images, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yYuuempsTclh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2.) **Deeper Architecture w/ More Layers and Filters, Drop-Out, and L2 Regularizer**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pI63Qug9Xqs3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape= (32,32,3), strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.30),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.35),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.40),\n",
        "  \n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.50),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "epochs = 50\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,  \n",
        "                      validation_data=(val_images, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F1XhcW6I-IrC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3) Adding Data Augmentation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mG8t5RlFS9PG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.15,\n",
        "        height_shift_range=0.15,\n",
        "        shear_range=0.15,\n",
        "        zoom_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "datagen.fit(train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5xQyvkb2_Fnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1111
        },
        "outputId": "e87dce3e-2cc8-4ec1-e76e-f052d68042c6"
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape= (32,32,3), strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.30),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.35),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.40),\n",
        "  \n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.50),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,980,010\n",
            "Trainable params: 4,980,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnWytUzhB8yD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4259
        },
        "outputId": "b2c77acd-b1a2-47a3-fddf-fbf8ca39b81c"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# model.fit_generator(datagen.flow(train_images, train_labels, batch_size=32),\\\n",
        "#                     steps_per_epoch=train_images.shape[0] // batch_size, epochs=50,\\\n",
        "#                     verbose=1,validation_data=(val_images,val_labels))\n",
        "\n",
        "model.fit_generator(datagen.flow(train_images, train_labels, batch_size=32), steps_per_epoch=train_images.shape[0] // batch_size, epochs= 80, verbose=1, validation_data=(val_images,val_labels))\n",
        "\n",
        "model.save('model3.h5')\n",
        "print(\"Model saved to disk\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "10000/10000 [==============================] - 4s 405us/sample - loss: 1.3815 - acc: 0.5429\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 1.4873 - acc: 0.5021 - val_loss: 1.3819 - val_acc: 0.5429\n",
            "Epoch 2/80\n",
            "10000/10000 [==============================] - 4s 380us/sample - loss: 1.3159 - acc: 0.5678\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.4597 - acc: 0.5162 - val_loss: 1.3164 - val_acc: 0.5678\n",
            "Epoch 3/80\n",
            "10000/10000 [==============================] - 4s 377us/sample - loss: 1.3353 - acc: 0.5578\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.4273 - acc: 0.5351 - val_loss: 1.3362 - val_acc: 0.5578\n",
            "Epoch 4/80\n",
            "10000/10000 [==============================] - 4s 374us/sample - loss: 1.2198 - acc: 0.6031\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.4067 - acc: 0.5444 - val_loss: 1.2199 - val_acc: 0.6031\n",
            "Epoch 5/80\n",
            "10000/10000 [==============================] - 4s 378us/sample - loss: 1.1757 - acc: 0.6162\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.3917 - acc: 0.5487 - val_loss: 1.1760 - val_acc: 0.6162\n",
            "Epoch 6/80\n",
            "10000/10000 [==============================] - 4s 375us/sample - loss: 1.3398 - acc: 0.5700\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.3726 - acc: 0.5626 - val_loss: 1.3399 - val_acc: 0.5700\n",
            "Epoch 7/80\n",
            "10000/10000 [==============================] - 4s 376us/sample - loss: 1.4339 - acc: 0.5577\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.3606 - acc: 0.5717 - val_loss: 1.4337 - val_acc: 0.5577\n",
            "Epoch 8/80\n",
            "10000/10000 [==============================] - 4s 380us/sample - loss: 1.2015 - acc: 0.6137\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.3551 - acc: 0.5738 - val_loss: 1.2019 - val_acc: 0.6137\n",
            "Epoch 9/80\n",
            "10000/10000 [==============================] - 4s 387us/sample - loss: 1.1679 - acc: 0.6369\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.3349 - acc: 0.5805 - val_loss: 1.1685 - val_acc: 0.6369\n",
            "Epoch 10/80\n",
            "10000/10000 [==============================] - 4s 383us/sample - loss: 1.3217 - acc: 0.5862\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.3339 - acc: 0.5853 - val_loss: 1.3225 - val_acc: 0.5862\n",
            "Epoch 11/80\n",
            "10000/10000 [==============================] - 4s 386us/sample - loss: 1.1560 - acc: 0.6351\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.3195 - acc: 0.5925 - val_loss: 1.1561 - val_acc: 0.6351\n",
            "Epoch 12/80\n",
            "10000/10000 [==============================] - 4s 375us/sample - loss: 1.2912 - acc: 0.5990\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.3103 - acc: 0.5946 - val_loss: 1.2919 - val_acc: 0.5990\n",
            "Epoch 13/80\n",
            "10000/10000 [==============================] - 4s 382us/sample - loss: 1.1772 - acc: 0.6312\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.3017 - acc: 0.6001 - val_loss: 1.1776 - val_acc: 0.6312\n",
            "Epoch 14/80\n",
            "10000/10000 [==============================] - 4s 373us/sample - loss: 1.3731 - acc: 0.5878\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.3045 - acc: 0.6001 - val_loss: 1.3737 - val_acc: 0.5878\n",
            "Epoch 15/80\n",
            "10000/10000 [==============================] - 4s 382us/sample - loss: 1.1303 - acc: 0.6484\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.2861 - acc: 0.6083 - val_loss: 1.1303 - val_acc: 0.6484\n",
            "Epoch 16/80\n",
            "10000/10000 [==============================] - 4s 387us/sample - loss: 1.1869 - acc: 0.6304\n",
            "1250/1250 [==============================] - 58s 46ms/step - loss: 1.2867 - acc: 0.6119 - val_loss: 1.1867 - val_acc: 0.6304\n",
            "Epoch 17/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.2611 - acc: 0.6030\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2705 - acc: 0.6152 - val_loss: 1.2616 - val_acc: 0.6030\n",
            "Epoch 18/80\n",
            "10000/10000 [==============================] - 4s 370us/sample - loss: 1.1646 - acc: 0.6333\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2761 - acc: 0.6176 - val_loss: 1.1650 - val_acc: 0.6333\n",
            "Epoch 19/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.1927 - acc: 0.6450\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2732 - acc: 0.6179 - val_loss: 1.1931 - val_acc: 0.6450\n",
            "Epoch 20/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.2958 - acc: 0.6285\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2633 - acc: 0.6241 - val_loss: 1.2962 - val_acc: 0.6285\n",
            "Epoch 21/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.2563 - acc: 0.6278\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2650 - acc: 0.6224 - val_loss: 1.2564 - val_acc: 0.6278\n",
            "Epoch 22/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.2052 - acc: 0.6201\n",
            "1250/1250 [==============================] - 56s 45ms/step - loss: 1.2570 - acc: 0.6314 - val_loss: 1.2055 - val_acc: 0.6201\n",
            "Epoch 23/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.2079 - acc: 0.6283\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2529 - acc: 0.6313 - val_loss: 1.2078 - val_acc: 0.6283\n",
            "Epoch 24/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.0945 - acc: 0.6756\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2589 - acc: 0.6282 - val_loss: 1.0944 - val_acc: 0.6756\n",
            "Epoch 25/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.0944 - acc: 0.6724\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2548 - acc: 0.6330 - val_loss: 1.0947 - val_acc: 0.6724\n",
            "Epoch 26/80\n",
            "10000/10000 [==============================] - 4s 371us/sample - loss: 1.2171 - acc: 0.6338\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2440 - acc: 0.6352 - val_loss: 1.2174 - val_acc: 0.6338\n",
            "Epoch 27/80\n",
            "10000/10000 [==============================] - 4s 371us/sample - loss: 1.0776 - acc: 0.6817\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2465 - acc: 0.6403 - val_loss: 1.0782 - val_acc: 0.6817\n",
            "Epoch 28/80\n",
            "10000/10000 [==============================] - 4s 370us/sample - loss: 1.1015 - acc: 0.6765\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2400 - acc: 0.6412 - val_loss: 1.1018 - val_acc: 0.6765\n",
            "Epoch 29/80\n",
            "10000/10000 [==============================] - 4s 371us/sample - loss: 1.1181 - acc: 0.6643\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2333 - acc: 0.6431 - val_loss: 1.1185 - val_acc: 0.6643\n",
            "Epoch 30/80\n",
            "10000/10000 [==============================] - 4s 373us/sample - loss: 1.1041 - acc: 0.6749\n",
            "1250/1250 [==============================] - 56s 45ms/step - loss: 1.2438 - acc: 0.6402 - val_loss: 1.1045 - val_acc: 0.6749\n",
            "Epoch 31/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.1957 - acc: 0.6546\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2327 - acc: 0.6449 - val_loss: 1.1960 - val_acc: 0.6546\n",
            "Epoch 32/80\n",
            "10000/10000 [==============================] - 4s 374us/sample - loss: 1.2165 - acc: 0.6565\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2247 - acc: 0.6471 - val_loss: 1.2169 - val_acc: 0.6565\n",
            "Epoch 33/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.0573 - acc: 0.6965\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2282 - acc: 0.6516 - val_loss: 1.0579 - val_acc: 0.6965\n",
            "Epoch 34/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.1067 - acc: 0.6809\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2220 - acc: 0.6499 - val_loss: 1.1070 - val_acc: 0.6809\n",
            "Epoch 35/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.2205 - acc: 0.6692\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2085 - acc: 0.6567 - val_loss: 1.2208 - val_acc: 0.6692\n",
            "Epoch 36/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.2238 - acc: 0.6547\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2235 - acc: 0.6521 - val_loss: 1.2239 - val_acc: 0.6547\n",
            "Epoch 37/80\n",
            "10000/10000 [==============================] - 4s 372us/sample - loss: 1.1303 - acc: 0.6685\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2242 - acc: 0.6519 - val_loss: 1.1305 - val_acc: 0.6685\n",
            "Epoch 38/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.1531 - acc: 0.6629\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2164 - acc: 0.6546 - val_loss: 1.1534 - val_acc: 0.6629\n",
            "Epoch 39/80\n",
            "10000/10000 [==============================] - 4s 370us/sample - loss: 1.0156 - acc: 0.7144\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2241 - acc: 0.6532 - val_loss: 1.0157 - val_acc: 0.7144\n",
            "Epoch 40/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.1569 - acc: 0.6792\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2088 - acc: 0.6617 - val_loss: 1.1571 - val_acc: 0.6792\n",
            "Epoch 41/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.0385 - acc: 0.7059\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2157 - acc: 0.6543 - val_loss: 1.0389 - val_acc: 0.7059\n",
            "Epoch 42/80\n",
            "10000/10000 [==============================] - 4s 370us/sample - loss: 1.0791 - acc: 0.6870\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2182 - acc: 0.6579 - val_loss: 1.0794 - val_acc: 0.6870\n",
            "Epoch 43/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.0850 - acc: 0.6944\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.2146 - acc: 0.6609 - val_loss: 1.0853 - val_acc: 0.6944\n",
            "Epoch 44/80\n",
            "10000/10000 [==============================] - 4s 370us/sample - loss: 1.2175 - acc: 0.6489\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1963 - acc: 0.6646 - val_loss: 1.2179 - val_acc: 0.6489\n",
            "Epoch 45/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.0482 - acc: 0.7059\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2111 - acc: 0.6589 - val_loss: 1.0487 - val_acc: 0.7059\n",
            "Epoch 46/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.0610 - acc: 0.7018\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2131 - acc: 0.6617 - val_loss: 1.0612 - val_acc: 0.7018\n",
            "Epoch 47/80\n",
            "10000/10000 [==============================] - 4s 370us/sample - loss: 1.0581 - acc: 0.7101\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2056 - acc: 0.6663 - val_loss: 1.0581 - val_acc: 0.7101\n",
            "Epoch 48/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.0570 - acc: 0.7116\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1962 - acc: 0.6651 - val_loss: 1.0570 - val_acc: 0.7116\n",
            "Epoch 49/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.0358 - acc: 0.7274\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.2032 - acc: 0.6659 - val_loss: 1.0365 - val_acc: 0.7274\n",
            "Epoch 50/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.1096 - acc: 0.6817\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1967 - acc: 0.6647 - val_loss: 1.1101 - val_acc: 0.6817\n",
            "Epoch 51/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.1486 - acc: 0.6824\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1954 - acc: 0.6667 - val_loss: 1.1487 - val_acc: 0.6824\n",
            "Epoch 52/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.1136 - acc: 0.6836\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1970 - acc: 0.6664 - val_loss: 1.1137 - val_acc: 0.6836\n",
            "Epoch 53/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.0860 - acc: 0.6941\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1856 - acc: 0.6697 - val_loss: 1.0861 - val_acc: 0.6941\n",
            "Epoch 54/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.0294 - acc: 0.7038\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1903 - acc: 0.6708 - val_loss: 1.0298 - val_acc: 0.7038\n",
            "Epoch 55/80\n",
            "10000/10000 [==============================] - 4s 375us/sample - loss: 1.0615 - acc: 0.7140\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1950 - acc: 0.6687 - val_loss: 1.0620 - val_acc: 0.7140\n",
            "Epoch 56/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.1055 - acc: 0.6766\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1918 - acc: 0.6684 - val_loss: 1.1058 - val_acc: 0.6766\n",
            "Epoch 57/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.1183 - acc: 0.6905\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1826 - acc: 0.6721 - val_loss: 1.1185 - val_acc: 0.6905\n",
            "Epoch 58/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.1184 - acc: 0.6903\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1946 - acc: 0.6693 - val_loss: 1.1185 - val_acc: 0.6903\n",
            "Epoch 59/80\n",
            "10000/10000 [==============================] - 4s 372us/sample - loss: 1.1146 - acc: 0.6889\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1840 - acc: 0.6718 - val_loss: 1.1147 - val_acc: 0.6889\n",
            "Epoch 60/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.1455 - acc: 0.6674\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1830 - acc: 0.6722 - val_loss: 1.1457 - val_acc: 0.6674\n",
            "Epoch 61/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.1332 - acc: 0.6855\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1862 - acc: 0.6731 - val_loss: 1.1332 - val_acc: 0.6855\n",
            "Epoch 62/80\n",
            "10000/10000 [==============================] - 4s 371us/sample - loss: 1.0176 - acc: 0.7173\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1851 - acc: 0.6714 - val_loss: 1.0176 - val_acc: 0.7173\n",
            "Epoch 63/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.0867 - acc: 0.7038\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1625 - acc: 0.6793 - val_loss: 1.0866 - val_acc: 0.7038\n",
            "Epoch 64/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.0640 - acc: 0.7040\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1752 - acc: 0.6740 - val_loss: 1.0643 - val_acc: 0.7040\n",
            "Epoch 65/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.3416 - acc: 0.6530\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1803 - acc: 0.6722 - val_loss: 1.3421 - val_acc: 0.6530\n",
            "Epoch 66/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 0.9798 - acc: 0.7371\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1824 - acc: 0.6750 - val_loss: 0.9800 - val_acc: 0.7371\n",
            "Epoch 67/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.0764 - acc: 0.6862\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1716 - acc: 0.6777 - val_loss: 1.0769 - val_acc: 0.6862\n",
            "Epoch 68/80\n",
            "10000/10000 [==============================] - 4s 365us/sample - loss: 1.0155 - acc: 0.7168\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1776 - acc: 0.6784 - val_loss: 1.0157 - val_acc: 0.7168\n",
            "Epoch 69/80\n",
            "10000/10000 [==============================] - 4s 365us/sample - loss: 1.1244 - acc: 0.6890\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1759 - acc: 0.6772 - val_loss: 1.1246 - val_acc: 0.6890\n",
            "Epoch 70/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.0313 - acc: 0.7146\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1736 - acc: 0.6775 - val_loss: 1.0316 - val_acc: 0.7146\n",
            "Epoch 71/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.1383 - acc: 0.6816\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1733 - acc: 0.6774 - val_loss: 1.1388 - val_acc: 0.6816\n",
            "Epoch 72/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.0691 - acc: 0.7027\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1621 - acc: 0.6816 - val_loss: 1.0696 - val_acc: 0.7027\n",
            "Epoch 73/80\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 1.0693 - acc: 0.7099\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1692 - acc: 0.6775 - val_loss: 1.0695 - val_acc: 0.7099\n",
            "Epoch 74/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.1394 - acc: 0.6902\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1682 - acc: 0.6800 - val_loss: 1.1397 - val_acc: 0.6902\n",
            "Epoch 75/80\n",
            "10000/10000 [==============================] - 4s 368us/sample - loss: 1.1354 - acc: 0.6867\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1691 - acc: 0.6791 - val_loss: 1.1358 - val_acc: 0.6867\n",
            "Epoch 76/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.1213 - acc: 0.6824\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1625 - acc: 0.6830 - val_loss: 1.1219 - val_acc: 0.6824\n",
            "Epoch 77/80\n",
            "10000/10000 [==============================] - 4s 369us/sample - loss: 1.0287 - acc: 0.7289\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1640 - acc: 0.6828 - val_loss: 1.0290 - val_acc: 0.7289\n",
            "Epoch 78/80\n",
            "10000/10000 [==============================] - 4s 379us/sample - loss: 1.1331 - acc: 0.6954\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1697 - acc: 0.6812 - val_loss: 1.1337 - val_acc: 0.6954\n",
            "Epoch 79/80\n",
            "10000/10000 [==============================] - 4s 371us/sample - loss: 0.9735 - acc: 0.7292\n",
            "1250/1250 [==============================] - 57s 46ms/step - loss: 1.1582 - acc: 0.6849 - val_loss: 0.9734 - val_acc: 0.7292\n",
            "Epoch 80/80\n",
            "10000/10000 [==============================] - 4s 367us/sample - loss: 1.0833 - acc: 0.6992\n",
            "1250/1250 [==============================] - 57s 45ms/step - loss: 1.1587 - acc: 0.6823 - val_loss: 1.0837 - val_acc: 0.6992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d37647908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "hKoLuAlSDraX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "3fdf1b9e-3b3e-4d0a-ea8a-c46fc59e959d"
      },
      "cell_type": "code",
      "source": [
        "new_model = keras.models.load_model('model3.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,980,010\n",
            "Trainable params: 4,980,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P5bPqonHD0NF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "377a1e15-a4e9-4ac5-f5e9-e193cca16ccd"
      },
      "cell_type": "code",
      "source": [
        "loss, acc = new_model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 357us/sample - loss: 1.1002 - acc: 0.6945\n",
            "Restored model, accuracy: 69.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9VtvyjKGEDT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}