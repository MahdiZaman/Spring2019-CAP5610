{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiZaman/Spring2019-CAP5610/blob/master/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Y2HofE0pHJZP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**************HW 2**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The goal of this homework is to create a convolutional neural network for the CIFAR10 data set. See this colab notebook how to load the CIFAR data in Keras.\n",
        "\n",
        "You should not use any pretrained convnets that come with Keras. You have to create and train your own convnets with Keras from scratch.\n",
        "\n",
        "\n",
        "\n",
        "*   Simple hold-out validation\n",
        "\n",
        "Make sure that the data is divided into:\n",
        "\n",
        "training set (80%)\n",
        "validation set (20%)\n",
        "test set.\n",
        "Use the training set to train your neural networks. Evaluate their performance on the validation data set.\n",
        "\n",
        "After trying several different architectures, choose the one that performs best of the validation set. Try at least four different architectures by using data augmentation, using dropout, varying the number of layers, the number of filters, etc.\n",
        "\n",
        "Train this final architecture on the data from the training set and validation set and evaluate its performance on the test set.\n",
        "\n",
        "*   k-fold validation\n",
        "\n",
        "Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "6Alftzj_PcHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Libraries and Loading Dataset**"
      ]
    },
    {
      "metadata": {
        "id": "ZCbODkRdEWWV",
        "colab_type": "code",
        "outputId": "ee8f3f02-d638-419e-f8fb-2127d9c504d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels) = cifar10.load_data()\n",
        "# (train_images_original, train_labels_original), (test_images_original, test_labels_n) = cifar10.load_data() #categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 20s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eGoDyDqmPlV3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Reshaping and Normalizing Training and Test Samples**"
      ]
    },
    {
      "metadata": {
        "id": "0uXQebz9lWmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images_rshp = train_images_original.reshape((train_images_original.shape[0], train_images_original.shape[1], train_images_original.shape[2], train_images_original.shape[3]))\n",
        "test_images_rshp = test_images_original.reshape((test_images_original.shape[0], test_images_original.shape[1], test_images_original.shape[2], test_images_original.shape[3]))\n",
        "\n",
        "train_images_n = train_images_rshp.astype('float32') / 255.0\n",
        "test_images = test_images_rshp.astype('float32') / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7wdFvhgPwYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Simple Hold-out Validation***"
      ]
    },
    {
      "metadata": {
        "id": "F32NQol4aA57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indices = np.random.permutation(train_images_original.shape[0])\n",
        "val_indcs = indices[0:10000]\n",
        "val_images = train_images_n[val_indcs]\n",
        "val_labels = train_labels_original[val_indcs]\n",
        "# val_labels_n = train_labels_original[val_indcs] #categorical\n",
        "\n",
        "\n",
        "train_indcs = indices[10000:]\n",
        "train_images = train_images_n[train_indcs]\n",
        "train_labels = train_labels_original[train_indcs]\n",
        "# train_labels_n = train_labels_original[train_indcs] #categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVCQ_gA3O5r1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_labels = np_utils.to_categorical(train_labels_n, 10)\n",
        "# val_labels = np_utils.to_categorical(val_labels_n, 10)\n",
        "# test_labels = np_utils.to_categorical(test_labels_n, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L894H3F8_pe8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initializations\n",
        "\n",
        "weight_decay = 1e-4  #For Kernel Regularizers\n",
        "epochs = 80\n",
        "batch_size=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fW4lVIVvTHMR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.) **Baseline Model**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DEzuqM-_HKYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set up the layers\n",
        "## Baseline\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    #\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    #\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    #\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=50,  \n",
        "                      validation_data=(val_images, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yYuuempsTclh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2.) **Deeper Architecture w/ More Layers and Filters, Drop-Out, and L2 Regularizer**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pI63Qug9Xqs3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape= (32,32,3), strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.30),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.35),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.40),\n",
        "  \n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.50),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "epochs = 50\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,  \n",
        "                      validation_data=(val_images, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F1XhcW6I-IrC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3) Adding Data Augmentation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mG8t5RlFS9PG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.15,\n",
        "        height_shift_range=0.15,\n",
        "        shear_range=0.15,\n",
        "        zoom_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "datagen.fit(train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5xQyvkb2_Fnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1111
        },
        "outputId": "e87dce3e-2cc8-4ec1-e76e-f052d68042c6"
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape= (32,32,3), strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.30),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.35),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.40),\n",
        "  \n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.Conv2D(512, (3,3), activation='relu', padding='same', strides= (1,1), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    keras.layers.MaxPooling2D((2, 2), padding= 'same'),\n",
        "    keras.layers.Dropout(0.50),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,980,010\n",
            "Trainable params: 4,980,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnWytUzhB8yD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fb189571-a97e-45b7-9430-860bd0523962"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# model.fit_generator(datagen.flow(train_images, train_labels, batch_size=32),\\\n",
        "#                     steps_per_epoch=train_images.shape[0] // batch_size, epochs=50,\\\n",
        "#                     verbose=1,validation_data=(val_images,val_labels))\n",
        "\n",
        "model.fit_generator(datagen.flow(train_images, train_labels, batch_size=32), steps_per_epoch=train_images.shape[0] // batch_size, epochs= 50, verbose=1, validation_data=(val_images,val_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 186/1250 [===>..........................] - ETA: 1:10 - loss: 2.6733 - acc: 0.1198"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gWKqO01JZWrn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}