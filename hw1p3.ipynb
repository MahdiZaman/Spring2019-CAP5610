{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1p3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiZaman/Spring2019-CAP5610/blob/master/hw1p3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kCfXMzbGdKBw",
        "colab_type": "code",
        "outputId": "236a7e52-60d5-4606-e9d2-26a64947abee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4bvTBfqgWuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preparing the Train and Test Images (Adding a column of 1s for biases)\n",
        "nfeatures = 28*28\n",
        "nclasses = 10\n",
        "ntrainsamples = train_images_original.shape[0] #60000\n",
        "ntestsamples = test_images_original.shape[0]   #10000\n",
        "\n",
        "#normalizing inputs\n",
        "train_images = train_images_original.reshape((ntrainsamples, nfeatures))\n",
        "train_images = train_images.astype('float32') / 255 \n",
        "test_images = test_images_original.reshape((ntestsamples, nfeatures))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "#adding a column of 1s for bias calculation\n",
        "train_images_b = np.c_[np.ones((ntrainsamples, 1)), train_images]\n",
        "test_images_b = np.c_[np.ones((ntestsamples,1)), test_images]\n",
        "\n",
        "# One hot encoding for train and test labels\n",
        "train_labels = np.eye(nclasses)[train_labels_original]\n",
        "test_labels = np.eye(nclasses)[test_labels_original]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQYpI6EIqoCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "    z -= np.max(z)\n",
        "    a = (np.exp(z).T/ np.sum(np.exp(z), axis=1)).T\n",
        "    return a\n",
        "#   return np.exp(z) / np.sum(np.exp(z), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWOP1auUzV9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cce_loss(y, y_hat):\n",
        "    return -np.mean(y * np.log(y_hat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Sqqglktzyvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forwardprop(x, weight):\n",
        "    xw = x.dot(weight)\n",
        "    A = softmax(xw)\n",
        "    return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-E7-STmo6PI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deriv(train_images, train_labels, a , minibatch):\n",
        "    dz = (a - train_labels) / minibatch\n",
        "    dw = np.dot(train_images_m.T , dz)\n",
        "    return dw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IIILZgtWs3pG",
        "colab_type": "code",
        "outputId": "e8d65a20-5567-4ac5-8ed6-f039c680d2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "## Training the model\n",
        "\n",
        "#initializing Weights and Bias(Bias added as a column of 1 on the left in weight array)\n",
        "\n",
        "initial_weight = np.zeros((nfeatures+1, nclasses))\n",
        "print(initial_weight.shape)\n",
        "\n",
        "weight = initial_weight\n",
        "weight_path_mgd = []\n",
        "weight_path_mgd.append(weight)\n",
        "\n",
        "epochs = 20 #number of epochs\n",
        "minibatchsize = 64 #number of samples in minibatch\n",
        "lr = 0.01 #Learning Rate\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    #shuffling the samples\n",
        "    m = np.random.permutation(ntrainsamples)\n",
        "    train_images_b = train_images_b[m]\n",
        "    train_labels = train_labels[m]\n",
        "    \n",
        "    #minibatch SGD\n",
        "    for i in range(0, ntrainsamples, minibatchsize):\n",
        "        train_images_m = train_images_b[i : i+minibatchsize] \n",
        "        train_labels_m = train_labels[i : i+minibatchsize]\n",
        "    \n",
        "        A = forwardprop(train_images_m, weight)\n",
        "        loss = cce_loss(train_labels_m, A)\n",
        "        \n",
        "        # Updating Weights and Biases\n",
        "        dw = deriv(train_images_m, train_labels_m, A , minibatchsize)\n",
        "        weight = weight - lr*dw\n",
        "        weight_path_mgd.append(weight)\n",
        "# print(len(weight_path_mgd))\n",
        "    print(('Epoch {}/{} --- Training Loss {}'.format(epoch+1 , epochs, np.mean(loss))))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(785, 10)\n",
            "Epoch 1/20 --- Training Loss 0.05548332228351912\n",
            "Epoch 2/20 --- Training Loss 0.030156498600664227\n",
            "Epoch 3/20 --- Training Loss 0.03079828581628974\n",
            "Epoch 4/20 --- Training Loss 0.045933934421422754\n",
            "Epoch 5/20 --- Training Loss 0.05249856679082815\n",
            "Epoch 6/20 --- Training Loss 0.029206016417257834\n",
            "Epoch 7/20 --- Training Loss 0.026848635347106888\n",
            "Epoch 8/20 --- Training Loss 0.04548747295079832\n",
            "Epoch 9/20 --- Training Loss 0.021561532289643935\n",
            "Epoch 10/20 --- Training Loss 0.03929771790772706\n",
            "Epoch 11/20 --- Training Loss 0.03072523230980017\n",
            "Epoch 12/20 --- Training Loss 0.049719978665543806\n",
            "Epoch 13/20 --- Training Loss 0.03425597085926725\n",
            "Epoch 14/20 --- Training Loss 0.024418217275167957\n",
            "Epoch 15/20 --- Training Loss 0.023774203490167754\n",
            "Epoch 16/20 --- Training Loss 0.015480698810844035\n",
            "Epoch 17/20 --- Training Loss 0.05583594613323871\n",
            "Epoch 18/20 --- Training Loss 0.04816111258294149\n",
            "Epoch 19/20 --- Training Loss 0.02096404802726402\n",
            "Epoch 20/20 --- Training Loss 0.014194005422854044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M1RFIC9e3eI6",
        "colab_type": "code",
        "outputId": "4f012112-7d66-422b-9934-d6333f33be28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "## Testing the model\n",
        "\n",
        "test_label_predicted = np.argmax(forwardprop(test_images_b, weight) , axis = 1)\n",
        "accuracy = np.sum(test_label_predicted == test_labels_original)/test_labels_original.shape[0] \n",
        "\n",
        "t = 200\n",
        "print(test_labels_original[t])\n",
        "print(test_label_predicted[t])\n",
        "print(\"Accuracy is {}\".format(accuracy))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n",
            "Accuracy is 0.9159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A532AGHhriKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSoKQY4cvJfS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}