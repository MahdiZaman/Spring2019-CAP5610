{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1p3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiZaman/Spring2019-CAP5610/blob/master/hw1p3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kCfXMzbGdKBw",
        "colab_type": "code",
        "outputId": "302dbd3e-1fdb-48ca-974d-19ce9af9b442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4bvTBfqgWuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preparing the Train and Test Images (Adding a column of 1s for biases)\n",
        "\n",
        "nfeatures = 28*28\n",
        "nclasses = 10\n",
        "ntrainsamples = train_images_original.shape[0] #60000\n",
        "ntestsamples = test_images_original.shape[0]   #10000\n",
        "\n",
        "#normalizing inputs\n",
        "train_images = train_images_original.reshape((ntrainsamples, nfeatures))\n",
        "train_images = train_images.astype('float32') / 255 \n",
        "test_images = test_images_original.reshape((ntestsamples, nfeatures))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "#adding a column of 1s for bias calculation\n",
        "train_images_b = np.c_[np.ones((ntrainsamples, 1)), train_images]\n",
        "test_images_b = np.c_[np.ones((ntestsamples,1)), test_images]\n",
        "\n",
        "# One hot encoding for train and test labels\n",
        "train_labels = np.eye(10)[train_labels_original]\n",
        "test_labels = np.eye(10)[test_labels_original]\n",
        "# print(train_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQYpI6EIqoCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "#     z -= np.max(z)\n",
        "#     a = (np.exp(z).T/ np.sum(np.exp(z), axis=1)).T\n",
        "#     return a\n",
        "    return np.exp(z) / np.sum(np.exp(z), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sWn5B6gxEkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "050439e1-c52b-49cc-8756-24754145f1f0"
      },
      "cell_type": "code",
      "source": [
        "a = [[1,2],[3,4]]\n",
        "print(np.max(a, axis = 1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tWOP1auUzV9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cce_loss(y, y_hat):\n",
        "    return -np.mean(y * np.log(y_hat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Sqqglktzyvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forwardprop(x, weight):\n",
        "    xw = x.dot(weight)\n",
        "    A = softmax(xw)\n",
        "    return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-E7-STmo6PI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deriv(train_images, train_labels, a , minibatch):\n",
        "    dz = (a - train_labels) / minibatch\n",
        "    dw = np.dot(train_images_m.T , dz)\n",
        "    return dw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IIILZgtWs3pG",
        "colab_type": "code",
        "outputId": "37faa23a-32d6-482d-9fbc-69972b311c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "cell_type": "code",
      "source": [
        "#initializing Weights and Bias(Bias added as a column of 1 on the left in weight array)\n",
        "\n",
        "initial_weight = np.random.randn(nfeatures+1, nclasses)\n",
        "print(initial_weight.shape)\n",
        "\n",
        "weight = initial_weight\n",
        "weight_path_mgd = []\n",
        "weight_path_mgd.append(weight)\n",
        "\n",
        "epochs = 10\n",
        "minibatchsize = 64\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    #shuffling the samples\n",
        "    m = np.random.permutation(ntrainsamples)\n",
        "    train_images_b = train_images_b[m]\n",
        "    train_labels = train_labels[m]\n",
        "    \n",
        "    #minibatch SGD\n",
        "    for i in range(0, ntrainsamples, minibatchsize):\n",
        "        train_images_m = train_images_b[i : i+minibatchsize] \n",
        "#       print(train_images_m.shape)\n",
        "        train_labels_m = train_labels[i : i+minibatchsize]\n",
        "        #if train_images_m.shape[0] != 128: print(i+minibatchsize)\n",
        "    \n",
        "        A = forwardprop(train_images_m, weight)\n",
        "        loss = cce_loss(train_labels_m, A)\n",
        "        \n",
        "        # Updating Weights and Biases\n",
        "        dw = deriv(train_images_m, train_labels_m, A , minibatchsize)\n",
        "        weight = weight - lr*dw\n",
        "        weight_path_mgd.append(weight)\n",
        "        \n",
        "    print(('Epoch {}/{} --- Training Loss {}'.format(epoch+1 , epochs, np.mean(loss))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(785, 10)\n",
            "Epoch 1/10 --- Training Loss 1.9942699494480878\n",
            "Epoch 2/10 --- Training Loss 3.701164982965333\n",
            "Epoch 3/10 --- Training Loss 3.6011868109732057\n",
            "Epoch 4/10 --- Training Loss 5.424619440400351\n",
            "Epoch 5/10 --- Training Loss 9.551945519455282\n",
            "Epoch 6/10 --- Training Loss 4.9948290136081415\n",
            "Epoch 7/10 --- Training Loss 7.907733094403935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-895647d2b254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#if train_images_m.shape[0] != 128: print(i+minibatchsize)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-86da9c40b57e>\u001b[0m in \u001b[0;36mforwardprop\u001b[0;34m(x, weight)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforwardprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mxw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "M1RFIC9e3eI6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_label_predicted = np.argmax(forwardprop(test_images_b, weight) , axis = 1)\n",
        "# accuracy = np.sum(test_label_predicted == test_labels_original)/test_labels_original.shape[0] \n",
        "\n",
        "accuracy = np.sum(test_label_predicted == test_labels_original)\n",
        "t = 2543\n",
        "print(test_labels_original[t])\n",
        "print(test_label_predicted[t])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A532AGHhriKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSoKQY4cvJfS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}