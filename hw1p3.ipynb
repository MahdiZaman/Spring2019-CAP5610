{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1p3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiZaman/Spring2019-CAP5610/blob/master/hw1p3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kCfXMzbGdKBw",
        "colab_type": "code",
        "outputId": "924e1c05-d1fd-40e5-9298-41dff614770f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4bvTBfqgWuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preparing the Train and Test Images (Adding a column of 1s for biases)\n",
        "nfeatures = 28*28\n",
        "nclasses = 10\n",
        "ntrainsamples = train_images_original.shape[0] #60000\n",
        "ntestsamples = test_images_original.shape[0]   #10000\n",
        "\n",
        "#normalizing inputs\n",
        "train_images = train_images_original.reshape((ntrainsamples, nfeatures))\n",
        "train_images = train_images.astype('float32') / 255 \n",
        "test_images = test_images_original.reshape((ntestsamples, nfeatures))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "#adding a column of 1s for bias calculation\n",
        "train_images_b = np.c_[np.ones((ntrainsamples, 1)), train_images]\n",
        "test_images_b = np.c_[np.ones((ntestsamples,1)), test_images]\n",
        "\n",
        "# One hot encoding for train and test labels\n",
        "train_labels = np.eye(nclasses)[train_labels_original]\n",
        "test_labels = np.eye(nclasses)[test_labels_original]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQYpI6EIqoCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax(z,n):\n",
        "#     z -= np.max(z)\n",
        "    mx = np.max(z, axis=1).reshape((n,1))\n",
        "    a = (np.exp(z-mx).T/ np.sum(np.exp(z-mx), axis=1)).T\n",
        "    return a\n",
        "#   return np.exp(z) / np.sum(np.exp(z), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWOP1auUzV9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cce_loss(y, y_hat):\n",
        "    return -np.mean(y * np.log(y_hat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Sqqglktzyvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forwardprop(x, weight, ninput):\n",
        "    xw = x.dot(weight)\n",
        "    A = softmax(xw,ninput)\n",
        "    return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-E7-STmo6PI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deriv(train_images, train_labels, a , minibatch):\n",
        "    dz = (a - train_labels) / minibatch\n",
        "    dw = np.dot(train_images_m.T , dz)\n",
        "    return dw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IIILZgtWs3pG",
        "colab_type": "code",
        "outputId": "853816b0-8d3c-46c0-9ce6-5d47ef4e4fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "## Training the model\n",
        "\n",
        "#initializing Weights and Bias(Bias added as a column of 1 on the left in weight array)\n",
        "\n",
        "initial_weight = np.zeros((nfeatures+1, nclasses))\n",
        "# print(initial_weight.shape)\n",
        "\n",
        "weight = initial_weight\n",
        "weight_path_mgd = []\n",
        "weight_path_mgd.append(weight)\n",
        "\n",
        "epochs = 20 #number of epochs\n",
        "minibatchsize = 40 #number of samples in minibatch\n",
        "lr = 0.01 #Learning Rate\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    #shuffling the samples\n",
        "    m = np.random.permutation(ntrainsamples)\n",
        "    train_images_b = train_images_b[m]\n",
        "    train_labels = train_labels[m]\n",
        "    \n",
        "    #minibatch SGD\n",
        "    for i in range(0, ntrainsamples, minibatchsize):\n",
        "        train_images_m = train_images_b[i : i+minibatchsize] \n",
        "        train_labels_m = train_labels[i : i+minibatchsize]\n",
        "    \n",
        "        A = forwardprop(train_images_m, weight, minibatchsize)\n",
        "        loss = cce_loss(train_labels_m, A)\n",
        "        \n",
        "        # Updating Weights and Biases\n",
        "        dw = deriv(train_images_m, train_labels_m, A , minibatchsize)\n",
        "        weight = weight - lr*dw\n",
        "        weight_path_mgd.append(weight)\n",
        "# print(len(weight_path_mgd))\n",
        "    print(('Epoch {}/{} --- Training Loss {}'.format(epoch+1 , epochs, np.mean(loss))))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20 --- Training Loss 0.05628928057333441\n",
            "Epoch 2/20 --- Training Loss 0.035495251241519636\n",
            "Epoch 3/20 --- Training Loss 0.02699361888330633\n",
            "Epoch 4/20 --- Training Loss 0.03041220496227872\n",
            "Epoch 5/20 --- Training Loss 0.03438563837541787\n",
            "Epoch 6/20 --- Training Loss 0.03605203722024967\n",
            "Epoch 7/20 --- Training Loss 0.03313417153549738\n",
            "Epoch 8/20 --- Training Loss 0.03445061341276188\n",
            "Epoch 9/20 --- Training Loss 0.030467990699211328\n",
            "Epoch 10/20 --- Training Loss 0.023898326004166567\n",
            "Epoch 11/20 --- Training Loss 0.053667549268827344\n",
            "Epoch 12/20 --- Training Loss 0.012550734359604063\n",
            "Epoch 13/20 --- Training Loss 0.020085943426151682\n",
            "Epoch 14/20 --- Training Loss 0.020581626935645136\n",
            "Epoch 15/20 --- Training Loss 0.02068311204240941\n",
            "Epoch 16/20 --- Training Loss 0.016315797953841894\n",
            "Epoch 17/20 --- Training Loss 0.03755968521649177\n",
            "Epoch 18/20 --- Training Loss 0.03260749327258059\n",
            "Epoch 19/20 --- Training Loss 0.038104650836653244\n",
            "Epoch 20/20 --- Training Loss 0.022948556301684957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M1RFIC9e3eI6",
        "colab_type": "code",
        "outputId": "ae7531ec-bdc6-4f21-e964-8abab6a470a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "## Testing the model\n",
        "\n",
        "test_label_predicted = np.argmax(forwardprop(test_images_b, weight, test_labels_original.shape[0]) , axis = 1)\n",
        "accuracy = np.sum(test_label_predicted == test_labels_original)/test_labels_original.shape[0] \n",
        "\n",
        "# t = 200\n",
        "# print(test_labels_original[t])\n",
        "# print(test_label_predicted[t])\n",
        "print(\"Accuracy is {}\".format(accuracy))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n",
            "Accuracy is 0.9195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A532AGHhriKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSoKQY4cvJfS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}