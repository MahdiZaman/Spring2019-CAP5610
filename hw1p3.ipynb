{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1p3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiZaman/Spring2019-CAP5610/blob/master/hw1p3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kCfXMzbGdKBw",
        "colab_type": "code",
        "outputId": "0e3b5d2c-30af-4bf4-d751-205b290e3797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4bvTBfqgWuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preparing the Train and Test Images (Adding a column of 1s for biases)\n",
        "nfeatures = 28*28\n",
        "nclasses = 10\n",
        "ntrainsamples = train_images_original.shape[0] #60000\n",
        "ntestsamples = test_images_original.shape[0]   #10000\n",
        "\n",
        "#normalizing inputs\n",
        "train_images = train_images_original.reshape((ntrainsamples, nfeatures))\n",
        "train_images = train_images.astype('float32') / 255 \n",
        "test_images = test_images_original.reshape((ntestsamples, nfeatures))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "#adding a column of 1s for bias calculation\n",
        "train_images_b = np.c_[np.ones((ntrainsamples, 1)), train_images]\n",
        "test_images_b = np.c_[np.ones((ntestsamples,1)), test_images]\n",
        "\n",
        "# One hot encoding for train and test labels\n",
        "train_labels = np.eye(nclasses)[train_labels_original]\n",
        "test_labels = np.eye(nclasses)[test_labels_original]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQYpI6EIqoCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax(z,n):\n",
        "#     z -= np.max(z)\n",
        "    mx = np.max(z, axis=1).reshape((n,1))\n",
        "    a = (np.exp(z-mx).T/ np.sum(np.exp(z-mx), axis=1)).T\n",
        "    return a\n",
        "#   return np.exp(z) / np.sum(np.exp(z), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWOP1auUzV9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cce_loss(y, y_hat):\n",
        "    return -np.mean(y * np.log(y_hat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Sqqglktzyvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forwardprop(x, weight, ninput):\n",
        "    xw = x.dot(weight)\n",
        "    A = softmax(xw,ninput)\n",
        "    return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-E7-STmo6PI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deriv(train_images, train_labels, a , minibatch):\n",
        "    dz = (a - train_labels) / minibatch\n",
        "    dw = np.dot(train_images_m.T , dz)\n",
        "    return dw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IIILZgtWs3pG",
        "colab_type": "code",
        "outputId": "623afff6-a9f4-4d56-829f-148d3a2bcecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "## Training the model\n",
        "\n",
        "#initializing Weights and Bias(Bias added as a column of 1 on the left in weight array)\n",
        "\n",
        "initial_weight = np.zeros((nfeatures+1, nclasses))\n",
        "# print(initial_weight.shape)\n",
        "\n",
        "weight = initial_weight\n",
        "weight_path_mgd = []\n",
        "weight_path_mgd.append(weight)\n",
        "\n",
        "epochs = 20 #number of epochs\n",
        "minibatchsize = 40 #number of samples in minibatch\n",
        "lr = 0.01 #Learning Rate\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    #shuffling the samples\n",
        "    m = np.random.permutation(ntrainsamples)\n",
        "    train_images_b = train_images_b[m]\n",
        "    train_labels = train_labels[m]\n",
        "    \n",
        "    #minibatch SGD\n",
        "    for i in range(0, ntrainsamples, minibatchsize):\n",
        "        train_images_m = train_images_b[i : i+minibatchsize] \n",
        "        train_labels_m = train_labels[i : i+minibatchsize]\n",
        "    \n",
        "        A = forwardprop(train_images_m, weight, minibatchsize)\n",
        "        loss = cce_loss(train_labels_m, A)\n",
        "        \n",
        "        # Updating Weights and Biases\n",
        "        dw = deriv(train_images_m, train_labels_m, A , minibatchsize)\n",
        "        weight = weight - lr*dw\n",
        "        weight_path_mgd.append(weight)\n",
        "# print(len(weight_path_mgd))\n",
        "    print(('Epoch {}/{} --- Training Loss {}'.format(epoch+1 , epochs, np.mean(loss))))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20 --- Training Loss 0.060122044491943576\n",
            "Epoch 2/20 --- Training Loss 0.05020662316250966\n",
            "Epoch 3/20 --- Training Loss 0.03483933942892684\n",
            "Epoch 4/20 --- Training Loss 0.04602639749953889\n",
            "Epoch 5/20 --- Training Loss 0.03787626744704162\n",
            "Epoch 6/20 --- Training Loss 0.02024916707055842\n",
            "Epoch 7/20 --- Training Loss 0.06307763536831894\n",
            "Epoch 8/20 --- Training Loss 0.03025975230207153\n",
            "Epoch 9/20 --- Training Loss 0.02740699543535266\n",
            "Epoch 10/20 --- Training Loss 0.029575026114214083\n",
            "Epoch 11/20 --- Training Loss 0.02548737363698044\n",
            "Epoch 12/20 --- Training Loss 0.040355299880436436\n",
            "Epoch 13/20 --- Training Loss 0.06335321517937123\n",
            "Epoch 14/20 --- Training Loss 0.018284982792312155\n",
            "Epoch 15/20 --- Training Loss 0.02661858610654939\n",
            "Epoch 16/20 --- Training Loss 0.02303173832916223\n",
            "Epoch 17/20 --- Training Loss 0.03532032434141179\n",
            "Epoch 18/20 --- Training Loss 0.038613572141493975\n",
            "Epoch 19/20 --- Training Loss 0.021854112418767703\n",
            "Epoch 20/20 --- Training Loss 0.024526112184580243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M1RFIC9e3eI6",
        "colab_type": "code",
        "outputId": "6d3675ae-f16f-484d-c640-a88c96a86f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "## Testing the model\n",
        "\n",
        "test_label_predicted = np.argmax(forwardprop(test_images_b, weight, test_labels_original.shape[0]) , axis = 1)\n",
        "accuracy = np.sum(test_label_predicted == test_labels_original)/test_labels_original.shape[0] \n",
        "\n",
        "# t = 200\n",
        "# print(test_labels_original[t])\n",
        "# print(test_label_predicted[t])\n",
        "print(\"Accuracy is {}\".format(accuracy))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.9193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A532AGHhriKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSoKQY4cvJfS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}